---
apiVersion: v1
kind: Service
metadata:
  name: kafka-svc
  labels:
    app: kafka
spec:
  ports:
  - port: 9093
    name: server
  clusterIP: None
  selector:
    app: kafka
---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: kafka-pdb
spec:
  selector:
    matchLabels:
      app: kafka
  minAvailable: 2
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-cm
data:
  server.properties: |
    listeners=PLAINTEXT://:9093
    zookeeper.connect={{ .Values.zookeeper-connect }}/kafka
    log.dir=/var/lib/kafka
    auto.create.topics.enable=true
    auto.leader.rebalance.enable=true
    background.threads=10
    compression.type=producer
    delete.topic.enable=false
    leader.imbalance.check.interval.seconds=300
    leader.imbalance.per.broker.percentage=10
    log.flush.interval.messages=9223372036854775807
    log.flush.offset.checkpoint.interval.ms=60000
    log.flush.scheduler.interval.ms=9223372036854775807
    log.retention.bytes=-1
    log.retention.hours=168
    log.roll.hours=168
    log.roll.jitter.hours=0
    log.segment.bytes=1073741824
    log.segment.delete.delay.ms=60000
    message.max.bytes=1000012
    min.insync.replicas=1
    num.io.threads=8
    num.network.threads=3
    num.recovery.threads.per.data.dir=1
    num.replica.fetchers=1
    offset.metadata.max.bytes=4096
    offsets.commit.required.acks=-1
    offsets.commit.timeout.ms=5000
    offsets.load.buffer.size=5242880
    offsets.retention.check.interval.ms=600000
    offsets.retention.minutes=1440
    offsets.topic.compression.codec=0
    offsets.topic.num.partitions=50
    offsets.topic.replication.factor=3
    offsets.topic.segment.bytes=104857600
    queued.max.requests=500
    quota.consumer.default=9223372036854775807
    quota.producer.default=9223372036854775807
    replica.fetch.min.bytes=1
    replica.fetch.wait.max.ms=500
    replica.high.watermark.checkpoint.interval.ms=5000
    replica.lag.time.max.ms=10000
    replica.socket.receive.buffer.bytes=65536
    replica.socket.timeout.ms=30000
    replica.fetch.backoff.ms=1000
    replica.fetch.max.bytes=1048576
    replica.fetch.response.max.bytes=10485760
    request.timeout.ms=30000
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600
    socket.send.buffer.bytes=102400
    unclean.leader.election.enable=true
    zookeeper.session.timeout.ms=6000
    zookeeper.set.acl=false
    broker.id.generation.enable=true
    connections.max.idle.ms=600000
    controlled.shutdown.enable=true
    controlled.shutdown.max.retries=3
    controlled.shutdown.retry.backoff.ms=5000
    controller.socket.timeout.ms=30000
    default.replication.factor=1
    fetch.purgatory.purge.interval.requests=1000
    group.max.session.timeout.ms=300000
    group.min.session.timeout.ms=6000
    inter.broker.protocol.version=0.10.2-IV0
    log.cleaner.backoff.ms=15000
    log.cleaner.dedupe.buffer.size=134217728
    log.cleaner.delete.retention.ms=86400000
    log.cleaner.enable=true
    log.cleaner.io.buffer.load.factor=0.9
    log.cleaner.io.buffer.size=524288
    log.cleaner.io.max.bytes.per.second=1.7976931348623157E308
    log.cleaner.min.cleanable.ratio=0.5
    log.cleaner.min.compaction.lag.ms=0
    log.cleaner.threads=1
    log.cleanup.policy=delete
    log.index.interval.bytes=4096
    log.index.size.max.bytes=10485760
    log.message.timestamp.difference.max.ms=9223372036854775807
    log.message.timestamp.type=CreateTime
    log.preallocate=false
    log.retention.check.interval.ms=300000
    max.connections.per.ip=2147483647
    num.partitions=1
    producer.purgatory.purge.interval.requests=1000
    reserved.broker.max.id=1000
---
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: kafka
spec:
  serviceName: kafka-svc
  replicas: 3
  template:
    metadata:
      labels:
        app: kafka
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: "app"
                    operator: In
                    values: 
                    - kafka
              topologyKey: "kubernetes.io/hostname"
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
             - weight: 1
               podAffinityTerm:
                 labelSelector:
                    matchExpressions:
                      - key: "app"
                        operator: In
                        values: 
                        - zk
                 topologyKey: "kubernetes.io/hostname"
      terminationGracePeriodSeconds: 300
      containers:
      - name: k8skafka
        imagePullPolicy: Always
        image: gcr.io/google_samples/k8skafka:v1
        resources:
          requests:
            memory: "1Gi"
            cpu: 500m
        ports:
        - containerPort: 9093
          name: server
        command:
        - sh
        - -c
        - "exec kafka-server-start.sh /opt/kafka/config/server.properties --override broker.id=${HOSTNAME##*-}"
        env:
        - name: KAFKA_HEAP_OPTS
          value : "-Xmx512M -Xms512M"
        - name: KAFKA_OPTS
          value: "-Dlogging.level=INFO"
        volumeMounts:
        - name: datadir
          mountPath: /var/lib/kafka
        - name: kafka-config
          mountPath: /opt/kafka/config/server.properties
          subPath: server.properties
        readinessProbe:
          exec:
           command: 
            - sh 
            - -c 
            - "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server=localhost:9093"
      volumes:
      - name: datadir
        hostPath:
          path: {{ .Values.hostpath }}
      - name: kafka-config
        configMap:
          name: kafka-cm
